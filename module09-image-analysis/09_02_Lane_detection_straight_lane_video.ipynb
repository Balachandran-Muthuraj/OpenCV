{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIAIuc3myCOI"
   },
   "source": [
    "<h1 style=\"font-size:30px;\">Application: Lane Detection in video</h1> \n",
    "\n",
    "This notebook will help you to detect lanes in a video using OpenCV. In the previous notebook, you learned how to detect lanes in a single image. In this notebook, you will see how to apply this pipeline to a video example, as well as consider of some of the limitations and possible extensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oZ7wcKMQyCOK"
   },
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Downloading Code to Colab Environment\")\n",
    "    !wget https://www.dropbox.com/sh/93k0ei59i6p554o/AAD1WAU_u25zZCs5LqyBDhaZa?dl=1 -O module-code.zip -q --show-progress\n",
    "    !unzip -qq module-code.zip\n",
    "else:\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SLRrQUqdyCOJ"
   },
   "source": [
    "from moviepy.editor import *\n",
    "clip = VideoFileClip('lane1-straight.mp4')\n",
    "clip.ipython_display(width = 800)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMntZ4IoyCOK"
   },
   "source": [
    "# 1. Define Utility Functions From Straight Lane Image\n",
    "\n",
    "Below are several utility functions that we will use to run our pipeline.\n",
    "\n",
    "### <font style='color:rgb(50,120,230)'> 1.1 Function from code ocvered in straight lane in image detection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jUekoER-yCOK"
   },
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"Select the region of interest (ROI) from a defined list of vertices.\"\"\"\n",
    "    # Defines a blank mask.\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    # Defining a 3 channel or 1 channel color to fill the mask.\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # 3 or 4 depending on your image.\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    # Filling pixels inside the polygon.\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels are nonzero.\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness = 2):\n",
    "    \"\"\"Utility for drawing lines.\"\"\"\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"Utility for defining Line Segments.\"\"\"\n",
    "    lines = cv2.HoughLinesP(\n",
    "        img, rho, theta, threshold, np.array([]),\n",
    "        minLineLength = min_line_len, maxLineGap = max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype = np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img, lines\n",
    "\n",
    "\n",
    "def separate_left_right_lines(lines):\n",
    "    \"\"\"Separate left and right lines depending on the slope.\"\"\"\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                if y1 > y2: # Negative slope = left lane.\n",
    "                    left_lines.append([x1, y1, x2, y2])\n",
    "                elif y1 < y2: # Positive slope = right lane.\n",
    "                    right_lines.append([x1, y1, x2, y2])\n",
    "    return left_lines, right_lines\n",
    "\n",
    "\n",
    "def cal_avg(values):\n",
    "    \"\"\"Calculate average value.\"\"\"\n",
    "    if not (type(values) == 'NoneType'):\n",
    "        if len(values) > 0:\n",
    "            n = len(values)\n",
    "        else:\n",
    "            n = 1\n",
    "        return sum(values) / n\n",
    "\n",
    "\n",
    "def extrapolate_lines(lines, upper_border, lower_border):\n",
    "    \"\"\"Extrapolate lines keeping in mind the lower and upper border intersections.\"\"\"\n",
    "    slopes = []\n",
    "    consts = []\n",
    "    \n",
    "    if (lines is not None) and (len(lines) != 0):\n",
    "        for x1, y1, x2, y2 in lines:\n",
    "            slope = (y1-y2) / (x1-x2)\n",
    "            slopes.append(slope)\n",
    "            c = y1 - slope * x1\n",
    "            consts.append(c)\n",
    "        avg_slope = cal_avg(slopes)\n",
    "        avg_consts = cal_avg(consts)\n",
    "\n",
    "        # Calculate average intersection at lower_border.\n",
    "        x_lane_lower_point = int((lower_border - avg_consts) / avg_slope)\n",
    "\n",
    "        # Calculate average intersection at upper_border.\n",
    "        x_lane_upper_point = int((upper_border - avg_consts) / avg_slope)\n",
    "\n",
    "        return [x_lane_lower_point, lower_border, x_lane_upper_point, upper_border]\n",
    "\n",
    "\n",
    "def extrapolated_lane_image(img, lines, roi_upper_border, roi_lower_border):\n",
    "    \"\"\"Main function called to get the final lane lines.\"\"\"\n",
    "    lanes_img = np.zeros((img.shape[0], img.shape[1], 3), dtype = np.uint8)\n",
    "    # Extract each lane.\n",
    "    lines_left, lines_right = separate_left_right_lines(lines)\n",
    "    lane_left = extrapolate_lines(lines_left, roi_upper_border, roi_lower_border)\n",
    "    lane_right = extrapolate_lines(lines_right, roi_upper_border, roi_lower_border)\n",
    "    if lane_left is not None and lane_right is not None:\n",
    "        draw_con(lanes_img, [[lane_left], [lane_right]])\n",
    "    return lanes_img\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtRMcnr_yCOL"
   },
   "source": [
    "### <font style='color:rgb(50,120,230)'> 1.2 New function for drawing area between the lanes.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-qSJWiNLyCOM"
   },
   "source": [
    "def draw_con(img, lines):\n",
    "    \"\"\"Fill in lane area.\"\"\"\n",
    "    points = []\n",
    "    for x1,y1,x2,y2 in lines[0]:\n",
    "        points.append([x1,y1])\n",
    "        points.append([x2,y2])\n",
    "    for x1,y1,x2,y2 in lines[1]:\n",
    "        points.append([x2,y2])\n",
    "        points.append([x1,y1])\n",
    "\n",
    "    points = np.array([points], dtype = 'int32')        \n",
    "    cv2.fillPoly(img, points, (0,255,0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVo6SVmvyCOM"
   },
   "source": [
    "# 2. Create the Main Process Loop Function\n",
    "\n",
    "This will be called over each frame of our dashcam video feed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pdclrddPyCOM"
   },
   "source": [
    "def process_image(image):  \n",
    "    # Convert to grayscale.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Intensity selection.\n",
    "    gray_select = cv2.inRange(gray, 150, 255)\n",
    "    \n",
    "    # Region masking: Select vertices according to the input image.\n",
    "    roi_vertices = np.array([[[100, 540], [900, 540], [525, 330], [440, 330]]])\n",
    "    gray_select_roi = region_of_interest(gray_select, roi_vertices)\n",
    "    \n",
    "    # Canny Edge Detection.\n",
    "    low_threshold = 50\n",
    "    high_threshold = 100\n",
    "    img_canny = cv2.Canny(gray_select_roi, low_threshold, high_threshold)\n",
    "    \n",
    "    # Remove noise using Gaussian blur.\n",
    "    kernel_size = 5\n",
    "    canny_blur = cv2.GaussianBlur(img_canny, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "    # Hough transform parameters set according to the input image.\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 100\n",
    "    min_line_len = 50\n",
    "    max_line_gap = 300\n",
    "    hough, lines = hough_lines(canny_blur, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "    \n",
    "    # Extrapolate lanes.\n",
    "    roi_upper_border = 330\n",
    "    roi_lower_border = 540\n",
    "    lane_img = extrapolated_lane_image(image, lines, roi_upper_border, roi_lower_border)\n",
    "    \n",
    "    # Combined using weighted image.\n",
    "    image_result = cv2.addWeighted(image, 1, lane_img, 0.4, 0.0)\n",
    "    return image_result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnuQO_EMyCON"
   },
   "source": [
    "# 3. Setup video capture\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
    "\n",
    "### <font color=\"green\">OpenCV Documentation</font>\n",
    "\n",
    "[**`VideoCapture()`**](https://docs.opencv.org/4.5.2/d8/dfe/classcv_1_1VideoCapture.html#ac4107fb146a762454a8a87715d9b7c96) \n",
    "\n",
    "[**`VideoWriter()`**](https://docs.opencv.org/4.5.2/dd/d9e/classcv_1_1VideoWriter.html#ad59c61d8881ba2b2da22cff5487465b5) \n",
    "\n",
    "[**`write()`**](https://docs.opencv.org/4.5.2/dd/d9e/classcv_1_1VideoWriter.html#a30ebbc09c122332f62bd706b43f02a98)\n",
    "\n",
    "[**`release()`**](https://docs.opencv.org/4.5.2/dd/d9e/classcv_1_1VideoWriter.html#a667f737e56d5ba6b0533c6c7bf941140) <br>\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "16jjA57XyCON"
   },
   "source": [
    "# Initialize our video capture.\n",
    "video_cap = cv2.VideoCapture('lane1-straight.mp4')\n",
    "if not video_cap.isOpened(): \n",
    "  print(\"Error opening video stream or file\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HvrzP1z9yCON"
   },
   "source": [
    "# Retrieve video frame properties.\n",
    "frame_w   = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h   = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Select fourcc encoding for the mp4 file.\n",
    "# Having issues? You could also try: *'mp4v' or *'avc1'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Specify the video output filenames.\n",
    "file_out = 'lane1-straight-output.mp4'\n",
    "\n",
    "# Create the video writer objects.\n",
    "vid_out = cv2.VideoWriter(file_out, fourcc, frame_fps, (frame_w,frame_h))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WEzUex8vyCON",
    "outputId": "77fb5d16-903d-4b2e-b59e-af7f2ef56540"
   },
   "source": [
    "# Run the main loop over every frame of the input video.\n",
    "print(\"Begin processing video... Wait until 'finished' message!\")\n",
    "while True:\n",
    "    ret, frame = video_cap.read()\n",
    "    if frame is None:\n",
    "        print(\"Finished processing video\")\n",
    "        break\n",
    "    result = process_image(frame)\n",
    "    vid_out.write(result)\n",
    "\n",
    "# Close the video writer stream.\n",
    "vid_out.release()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "40Dd9TQKyCOO"
   },
   "source": [
    "# Display the saved video file.\n",
    "from moviepy.editor import *\n",
    "clip = VideoFileClip(file_out)\n",
    "clip.ipython_display(width = 800)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hvHq3DoyCOO"
   },
   "source": [
    "\n",
    "Now you are able to detect straight lane lines. It is worth understanding some of the hard coded assumption this pipeline took around area of interest. You can consider possible extensions, such as detecting the horizon level and adjusting the size of the trapezoid region of interest accordingly.\n",
    "\n",
    "Furthermore, in real world scenario, the roads are not always straight. Additionally, sometimes the visibility might be low. You can go a step further and see how this pipeline performs over some extreme situations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "09_02_Lane_Detection_Straight_Lane_Video.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ebc319c8538a0dff9f27bfc0a3142b806f989e03741f3022156954c3f29d1992"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
